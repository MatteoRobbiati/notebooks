{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1199f9-0d44-4173-9496-a31189e1266f",
   "metadata": {},
   "source": [
    "## DBQAs as diagonalization algorithms\n",
    "\n",
    "Let us start from some basic imports (and eventually installations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abd963-9740-4999-9bf3-3c81b68ac10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install Qibo uncommenting and executing the following\n",
    "# !pip install qibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de82c3d-7e83-4801-9943-c647b4b35b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "        \n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output, display, Markdown\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optimization tool: evolutionary algorithm\n",
    "import cma\n",
    "\n",
    "import qibo\n",
    "from qibo import hamiltonians, set_backend\n",
    "from qibo.symbols import Z\n",
    "\n",
    "from qibo.models.dbi.double_bracket import (\n",
    "    # the DBI main class\n",
    "    DoubleBracketIteration,\n",
    "    # class which build the generator of the rotations\n",
    "    DoubleBracketGeneratorType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca970cad-471a-4978-90c1-bb944286fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following will help in reducing warnings outputs\n",
    "class SpecificWarningFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return (\n",
    "            \"Calculating the dense form of a symbolic Hamiltonian\"\n",
    "            not in record.getMessage()\n",
    "        )\n",
    "\n",
    "qibo_logger = qibo.config.log\n",
    "qibo_logger.addFilter(SpecificWarningFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4d6cf-2a44-4d17-813c-9d9a8191d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a Qibo backend\n",
    "# Use Qibojit for better performance when using more than 20 qubits\n",
    "set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29f558-d825-4cb3-88d7-819e3e1ec299",
   "metadata": {},
   "source": [
    "Let us add some plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2f85d-8047-497e-bb82-3406e9d41e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matrix(matrix, title=\"\"):\n",
    "    \"\"\"Visualize hamiltonian in a heatmap form.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_title(title)\n",
    "    # print the abs value of the components of the matrix\n",
    "    try:\n",
    "        im = ax.imshow(np.absolute(matrix), cmap=\"inferno\")\n",
    "    except TypeError:\n",
    "        im = ax.imshow(np.absolute(matrix.get()), cmap=\"inferno\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "def plot_loss(losses, steps, labels=[\"\"], title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot loss functions returned by many DBI iterations with two subplots:\n",
    "    - Left: Iteration vs Loss (original plot)\n",
    "    - Right: Cumulative steps vs Loss\n",
    "    \"\"\"\n",
    "    # Generate n colors\n",
    "    colors = [\"#ec6c6c\", \"#dc9d35\", \"#68da85\", \"#687fda\", \"#a768da\"]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    # Left subplot: Original plot\n",
    "    for i, loss in enumerate(losses):\n",
    "        axs[0].plot(loss, color=colors[i % len(colors)], marker=\"o\", label=labels[i])\n",
    "    axs[0].set_xlabel(\"Iteration\")\n",
    "    axs[0].set_ylabel(\"Off-diag norm\")\n",
    "    if len(labels) > 1:\n",
    "        axs[0].legend()\n",
    "    \n",
    "    # Right subplot: Cumulative steps vs Loss\n",
    "    for i, loss in enumerate(losses):\n",
    "        # Compute cumulative steps\n",
    "        cumulative_steps = np.cumsum(steps[i])\n",
    "        axs[1].plot(cumulative_steps, loss, color=colors[i % len(colors)], marker=\"o\", label=labels[i])\n",
    "    axs[1].set_xlabel(\"Time (cumulative s)\")\n",
    "    if len(labels) > 1:\n",
    "        axs[1].legend()\n",
    "    \n",
    "    # Overall title\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4aae03-c3d0-443a-98e3-67cce3b78fca",
   "metadata": {},
   "source": [
    "For the sake of this tutorial notebook, we will consider as input Hamiltonian a 1 dimensional Heisenberg XXZ. It is clearly a problem which can be addressed by using Tensor Network methods, or Bethe ansatze, but it will be used as illustrative example.\n",
    "Actually, for some of the DBIs we discuss below, a more complex (non integrable) model could be less problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745a2b4-1512-4a6f-9e1e-dcd4dd4b048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyper-parameters\n",
    "nqubits = 5\n",
    "nsteps = 10\n",
    "\n",
    "# Let's target the Heisenberg Hamiltonian\n",
    "h0 = hamiltonians.XXZ(nqubits=nqubits, delta=0.5, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a03913-9fb5-4222-9910-1f6c5d8d3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(h0.matrix, r\"$H_0$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14c81c",
   "metadata": {},
   "source": [
    "#### Recap of the DBI tools\n",
    "\n",
    "We target an input hamiltonian $\\hat{H}_0$, to which we apply a sequence of rotations:\n",
    "$$ \\hat{H}_{k+1} = e^{s_k \\hat{W}_k(\\vec{\\theta})} \\hat{H}_k e^{-s_k \\hat{W}_k(\\vec{\\theta})},$$\n",
    "where $s_k$ is the DBI step size and the rotation is generated by\n",
    "$$ \\hat{W}_k(\\vec{\\theta}) = [ \\hat{D}_k(\\vec{\\theta}), \\hat{H}_k]. $$\n",
    "\n",
    "We will optimize the DBI by finding optimal parameters $s_k$ and $\\vec{\\theta}$ in the second part of the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "To setup the double bracket quantum algorithm we have to decide which rotation generator to use. Let's list them and then start with the more natural one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2109b0d-5e01-4564-9576-1efe9e0012a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for generator in DoubleBracketGeneratorType:\n",
    "    print(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9c597-a588-463d-8058-20a84648f263",
   "metadata": {},
   "source": [
    "The canonical is the most natural choice:\n",
    "$$ \\hat{W}_k = [ \\hat{\\Delta}(\\hat{H}_k), \\hat{H}_k], $$\n",
    "where in practice we use the diagonal part of the input Hamiltonian as diagonal operator to construct the rotation generator. \n",
    "In this notebook we will make use of the canonical operator at first, and then we will switch to the group commutator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177efd50-970f-4ebd-9e5a-78acc0696b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = DoubleBracketGeneratorType.canonical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f54ca-b420-42b3-a187-a8698b301972",
   "metadata": {},
   "source": [
    "#### Execute one step of DBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2f957-220e-42d4-ab11-bc30a0563810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=canonical\n",
    ")\n",
    "\n",
    "print(f\"Off diagonal norm before applying DBI: {dbi.off_diagonal_norm}\")\n",
    "dbi(step=0.05)\n",
    "print(f\"Off diagonal norm after applying DBI: {dbi.off_diagonal_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c657349-7ca3-47e0-935b-dc002f5ca86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbi.h.matrix, r\"$H_1$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea849f-9445-42af-bd3d-20e174485aa3",
   "metadata": {},
   "source": [
    "#### Let's have a look to the class DBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65170f55-c87c-42eb-be09-5f75cbe5ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as Markdown\n",
    "attributes = [\n",
    "    attr for attr in dir(dbi) if not callable(getattr(dbi, attr)) \n",
    "    and not attr.startswith(\"__\")\n",
    "]\n",
    "methods = [\n",
    "    method for method in dir(dbi) if callable(getattr(dbi, method)) \n",
    "    and not method.startswith(\"__\")]\n",
    "\n",
    "# Build the Markdown content\n",
    "markdown_content = \"### Attributes:\\n- \" + \"\\n- \".join(attributes) + \"\\n\\n### Methods:\\n- \" + \"\\n- \".join(methods)\n",
    "\n",
    "# Display the content\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d4a5a-0de8-4ad0-850d-462e9632c9a5",
   "metadata": {},
   "source": [
    "#### Execute more steps of DBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4177202-66ff-470a-a28c-130a07e1783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_db_iterations(dbi, nsteps=30, stepsize=0.01, optimize_step=False, d=None):\n",
    "    \"\"\"Repeat `nsteps` times the DBI execution.\"\"\"\n",
    "    offdiag_norms = [dbi.off_diagonal_norm]\n",
    "    steps = [0.]\n",
    "    for _ in range(nsteps):\n",
    "        if optimize_step:\n",
    "            stepsize = optimize_stepsize(dbi=dbi, grid_size=100, d=d)\n",
    "        steps.append(stepsize)\n",
    "        dbi(step=stepsize, d=d)\n",
    "        offdiag_norms.append(dbi.off_diagonal_norm)\n",
    "    return offdiag_norms, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca1064-ac06-4c19-957f-182d63524b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize DBI\n",
    "dbi = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=canonical,\n",
    ")\n",
    "\n",
    "# execute ntimes\n",
    "offdiag_norms, steps_can = n_db_iterations(dbi=dbi, nsteps=nsteps)\n",
    "\n",
    "# plot the loss function\n",
    "plot_loss(losses=[offdiag_norms], steps=[steps_can])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330874a7-5a70-4409-b11f-5901e64b65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbi.h.matrix, r\"$H$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c7dfc-51e9-44c1-a81c-6656261db058",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_value = np.min(h0.eigenvalues())\n",
    "dbi_approx = np.real(np.min(dbi.diagonal_h_matrix))\n",
    "\n",
    "print(f\"Exact ground state energy: {exact_value}\")\n",
    "print(f\"GS Energy according to our diagonalization: {dbi_approx}\")\n",
    "print(f\"Absolute difference of the values: {np.abs(exact_value - dbi_approx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24a4de-8a36-448f-a56e-c2553086fb89",
   "metadata": {},
   "source": [
    "#### Optimize the step duration\n",
    "\n",
    "Let us start by implementing the simpler step optimization ever: a grid search.\n",
    "This is not optimal, but helps in understanding the importance of hyper-optimizing the DBI. Later in the notebook, we will adopt a smarter strategy to optimize the DBI parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb149a-c547-41cc-82aa-abdd270c240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_stepsize(dbi, d=None, step_range=[-5, 0], grid_size=30):\n",
    "    \"\"\"Optimize the stepsize on a grid of values.\"\"\"\n",
    "    step_grid = np.logspace(step_range[0], step_range[1], grid_size)\n",
    "\n",
    "    losses = [dbi.off_diagonal_norm]\n",
    "    for step in step_grid:\n",
    "        dbi_copy = deepcopy(dbi)\n",
    "        dbi_copy(step=step, d=d)\n",
    "        losses.append(dbi_copy.off_diagonal_norm)\n",
    "\n",
    "    return step_grid[np.argmin(losses) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7523a8-7f73-47e5-99ed-b92f5d6c432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the dbi into the initial configuration\n",
    "dbi_optimized = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=canonical,\n",
    ")\n",
    "\n",
    "# execute ntimes\n",
    "offdiag_opt, steps_can_opt = n_db_iterations(\n",
    "    dbi=dbi_optimized, \n",
    "    nsteps=nsteps, \n",
    "    optimize_step=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6756f-4108-45ad-b0c0-c0d0984f37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss function\n",
    "plot_loss(\n",
    "    losses=[\n",
    "        offdiag_norms, \n",
    "        offdiag_opt\n",
    "    ], \n",
    "    steps=[\n",
    "        steps_can,\n",
    "        steps_can_opt,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"Canonical NO-opt\", \n",
    "        \"Canonical s-opt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e31e9-3ac6-406f-b511-85eb7040894e",
   "metadata": {},
   "source": [
    "It seems we can converge faster, but with a similar limit plateau. Let's then change generator type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fe525-bd73-43b0-9784-bf591c06475d",
   "metadata": {},
   "source": [
    "#### Let's use an adaptive rotation generator \n",
    "\n",
    "Knowing our Hamiltonian has symmetries, we adopt a variational strategy to check if we manage to have a better performance in diagonalizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786733c-8273-4e8e-b67b-932ac358e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's choose the commutator generator\n",
    "comm_gen = DoubleBracketGeneratorType.group_commutator\n",
    "\n",
    "# a dummy diagonal operator\n",
    "d_op = np.diag(np.linspace(1,2**nqubits,2**nqubits))\n",
    "print(d_op)\n",
    "\n",
    "dbi_comm = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=comm_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44346cf0-fa73-4ec0-b545-0df9403769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "offdiag_comm, steps_comm = n_db_iterations(\n",
    "    dbi=dbi_comm, \n",
    "    nsteps=nsteps, \n",
    "    optimize_step=True, \n",
    "    d=d_op\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43727285-61a7-4717-ac6b-4400d4148ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss function\n",
    "plot_loss(\n",
    "    losses=[\n",
    "        offdiag_norms, \n",
    "        offdiag_opt, \n",
    "        offdiag_comm\n",
    "    ], \n",
    "    steps=[\n",
    "        steps_can,\n",
    "        steps_can_opt,\n",
    "        steps_comm,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"Canonical NO-opt\", \n",
    "        \"Canonical s-opt\", \n",
    "        \"Group commutator s-opt\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b555a9-1fce-4966-b282-78342c93e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(dbi_comm.h.matrix, r\"$H_{10}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2cd7d-7890-4dc6-ab70-2f773a2cc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_value = np.min(h0.eigenvalues())\n",
    "dbi_approx = np.real(np.min(dbi_comm.diagonal_h_matrix))\n",
    "\n",
    "print(f\"Exact ground state energy: {exact_value}\")\n",
    "print(f\"GS Energy according to our diagonalization: {dbi_approx}\")\n",
    "print(f\"Absolute difference of the values: {np.abs(exact_value - dbi_approx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e9164-1f93-4fba-b9ba-7ab717d926b4",
   "metadata": {},
   "source": [
    "#### Parametrize the D operator\n",
    "\n",
    "We can now try to do something better using the same DBI setup but playing around with the parameters of the $\\hat{D}$ operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094afb4-cecd-4c12-b6fb-366cf65223f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIM_d_operator(nqubits, params, print_symbolical=False):\n",
    "    \"\"\"\n",
    "    Parametrize the D operator in form of a classical Transverse Field Ising Model.\n",
    "\n",
    "    Args:\n",
    "        nqubits (int): number of qubits;\n",
    "        params (List[float]): list of coefficients for Z and Z * Z terms in TFIM. \n",
    "            It has to be 2 * nqubits long;\n",
    "    \"\"\"\n",
    "    symbolical_d = 0\n",
    "\n",
    "    for q in range(nqubits):\n",
    "        symbolical_d += params[::2][q] * Z(q)\n",
    "        symbolical_d += params[1::2][q] * Z(q) * Z((q + 1) % nqubits)\n",
    "\n",
    "    if print_symbolical:\n",
    "        print(symbolical_d)\n",
    "    \n",
    "    return hamiltonians.SymbolicHamiltonian(form=symbolical_d).matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9bbc8-f934-4b1d-bae7-358592469313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initialization for TFIM\n",
    "params = np.random.uniform(0., 3., 2 * nqubits)\n",
    "\n",
    "# setup the D operator\n",
    "d_op_tfim = TFIM_d_operator(nqubits, params, print_symbolical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f954a1-7c9a-430e-9029-0e8ae2fd1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(d_op_tfim, r\"$D(\\alpha, \\beta)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03001cd3-b4ed-4126-8de2-83b027363965",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi_comm_tfim = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=comm_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35c8aa-c6eb-46f2-84c3-305cfa35c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "offdiag_comm_tfim, steps_comm_tfim = n_db_iterations(\n",
    "    dbi=dbi_comm_tfim, \n",
    "    nsteps=nsteps, \n",
    "    optimize_step=True, \n",
    "    d=d_op_tfim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c29f2e-4c33-4187-9432-8154cc03275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(\n",
    "    losses=[\n",
    "        offdiag_norms, \n",
    "        offdiag_opt, \n",
    "        offdiag_comm, \n",
    "        offdiag_comm_tfim\n",
    "    ], \n",
    "    steps=[\n",
    "        steps_can,\n",
    "        steps_can_opt,\n",
    "        steps_comm,\n",
    "        steps_comm_tfim,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"Canonical NO-opt\", \n",
    "        \"Canonical s-opt\", \n",
    "        \"Group commutator s-opt\",\n",
    "        \"Group commutator s-opt d-TFIM NO-opt\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e406ec0-a088-424b-af9b-65ccc9a7b1ce",
   "metadata": {},
   "source": [
    "#### Optimize the D operator\n",
    "\n",
    "Now that $D$ has been parametrized, we can adopt a variational approach so that we minimize the number of steps required to reach a good diagonalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8065f9-0777-4f1c-8c1f-e2d4b9c44d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_dbi(\n",
    "    params, \n",
    "    dbi\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute loss function given a DBI configuration, namely given stepsize and the alphas and betas\n",
    "    which parametrize the D operator.\n",
    "\n",
    "    Args:\n",
    "        params (List[float]): variational parameters to be used in the DBI execution.\n",
    "            The list has to be such that params[0] is the initial stepsize, and then \n",
    "            params[1:-1] are (alpha, beta, alpha, beta ...) coefficients of the TFIM parametrization.\n",
    "        dbi (DoubleBracketIteration): double bracket iteration object.\n",
    "    \"\"\"\n",
    "    dbi_copy = deepcopy(dbi)\n",
    "    # collect parameters\n",
    "    d_op = TFIM_d_operator(dbi_copy.h.nqubits, params=params[1:])\n",
    "    dbi_copy(step=params[0], d=d_op)\n",
    "    return dbi_copy.off_diagonal_norm\n",
    "\n",
    "def optimize_DBI(\n",
    "    dbi, \n",
    "    params, \n",
    "    s_bounds=(1e-4, 1.), \n",
    "    b_bounds=(-9., 9.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimize all hyper-parameters of the DBI, namely the stepsize and the alphas and betas\n",
    "    which parametrize the D operator.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_bounds = s_bounds[0] + b_bounds[0] * (len(params) - 1)\n",
    "    upper_bounds = s_bounds[1] + b_bounds[1] * (len(params) - 1)\n",
    "    bounds = [lower_bounds, upper_bounds]\n",
    "    result = cma.fmin(\n",
    "        loss_function_dbi,\n",
    "        sigma0=0.5,\n",
    "        x0=params,\n",
    "        args=(dbi,),\n",
    "        options={\"bounds\": bounds, \"maxiter\": 100},\n",
    "    )[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda58fb-6f68-4876-b460-06f4657da700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DBI \n",
    "dbi_comm_tfim_opt = DoubleBracketIteration(\n",
    "    hamiltonian=deepcopy(h0), \n",
    "    mode=comm_gen\n",
    ")\n",
    "\n",
    "# Initial parameters\n",
    "params = [0.01]\n",
    "params.extend(np.random.uniform(0., 6., nqubits * 2))\n",
    "\n",
    "# We collect offdiag norm and steps\n",
    "offdiag_tfim_opt = [dbi_comm_tfim_opt.off_diagonal_norm]\n",
    "steps_comm_tfim_opt = [0.]\n",
    "\n",
    "# nsteps time optimization + DBI ex\n",
    "for n in range(nsteps):\n",
    "    print(\"#########################################\")\n",
    "    print(f\"Optimized procedure step {n+1}/{nsteps}\")\n",
    "    print(\"#########################################\\n\")\n",
    "    # Collect optimized DBI parameters, both stepsize and TFIM model's\n",
    "    best_params = optimize_DBI(dbi=dbi_comm_tfim_opt, params=params)\n",
    "    # Save the stepsize value\n",
    "    steps_comm_tfim_opt.append(np.abs(best_params[0]))\n",
    "    # Execute the DBI\n",
    "    dbi_comm_tfim_opt(\n",
    "        step=best_params[0], \n",
    "        d=TFIM_d_operator(nqubits, best_params[1:])\n",
    "    )\n",
    "    # Collect the off-diagonal norm value\n",
    "    offdiag_tfim_opt.append(dbi_comm_tfim_opt.off_diagonal_norm)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f4144-4234-4a8b-a4c0-4a44b3af4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(\n",
    "    losses=[\n",
    "        offdiag_norms, \n",
    "        offdiag_opt, \n",
    "        offdiag_comm, \n",
    "        offdiag_comm_tfim,\n",
    "        offdiag_tfim_opt,\n",
    "    ], \n",
    "    steps=[\n",
    "        steps_can,\n",
    "        steps_can_opt,\n",
    "        steps_comm,\n",
    "        steps_comm_tfim,\n",
    "        steps_comm_tfim_opt,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"Canonical NO-opt\", \n",
    "        \"Canonical s-opt\", \n",
    "        \"Group commutator s-opt\",\n",
    "        \"Group commutator s-opt d-TFIM NO-opt\",\n",
    "        \"Group commutator s-opt d-TFIM opt\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ad582-edeb-430b-8b62-4867d150d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_value = np.min(h0.eigenvalues())\n",
    "dbi_approx = np.real(np.min(dbi_comm_tfim_opt.diagonal_h_matrix))\n",
    "\n",
    "print(f\"Exact ground state energy: {exact_value}\")\n",
    "print(f\"GS Energy according to our diagonalization: {dbi_approx}\")\n",
    "print(f\"Absolute difference of the values: {np.abs(exact_value - dbi_approx)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
